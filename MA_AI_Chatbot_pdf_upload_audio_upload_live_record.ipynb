{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " \"**Meeting Assistant AI**\" app to allow live recording of the meeting along with maintaining the existing features (handling PDF, audio, and chatbot), you can use Python's sounddevice and wavio libraries to capture live audio, save it, and then use the captured audio for transcription and summarization."
      ],
      "metadata": {
        "id": "HuNlIriPPqcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:** Install Additional Dependencies\n",
        "\n",
        "We will need to install the sounddevice and wavio libraries for live audio recording."
      ],
      "metadata": {
        "id": "N5OYWJsUPu84"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX-HjSJgPCEL",
        "outputId": "e0410d4a-781a-4e33-e253-24fcebae03cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sounddevice in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
            "Requirement already satisfied: wavio in /usr/local/lib/python3.10/dist-packages (0.0.9)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from wavio) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install sounddevice\n",
        "!pip install wavio\n",
        "!pip install requests\n",
        "!pip install PyPDF2\n",
        "!pip install pydub\n",
        "!pip install SpeechRecognition\n",
        "!apt-get install ffmpeg  # Required for handling audio formats like mp3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2**: Import the Required Libraries\n",
        "\n",
        "You need to import the sounddevice library for live recording, wavio to save the recorded audio, and the rest of the libraries for the existing functionalities."
      ],
      "metadata": {
        "id": "isItzN_GPz1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install libportaudio2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wrg7EsP1ckBD",
        "outputId": "09c06d72-0650-4220-e45f-a0b72ce26ee6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libportaudio2 is already the newest version (19.6.0-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import PyPDF2\n",
        "from io import BytesIO\n",
        "from google.colab import files\n",
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr\n",
        "import sounddevice as sd\n",
        "import wavio\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "7rR6ZAnGP1rk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Live Recording Function\n",
        "\n",
        "Here, we define a function that records live audio from the user's microphone and saves it as a .wav file. You can adjust the duration and sampling rate as per your needs."
      ],
      "metadata": {
        "id": "1ozyzvMaP4Nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to record live audio\n",
        "def record_live_audio(duration=60, sample_rate=44100):\n",
        "    print(\"Recording audio for\", duration, \"seconds...\")\n",
        "\n",
        "    # Record audio with specified duration and sample rate\n",
        "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='int16')\n",
        "    sd.wait()  # Wait until the recording is finished\n",
        "\n",
        "    # Save the recording as a WAV file\n",
        "    wavio.write(\"live_recording.wav\", recording, sample_rate, sampwidth=2)\n",
        "    print(\"Recording saved as 'live_recording.wav'\")\n",
        "    return \"live_recording.wav\"\n"
      ],
      "metadata": {
        "id": "2FFf-2eGP7NF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function records the user's voice for a specified duration (default 60 seconds) and saves the audio as live_recording.wav. You can change the duration by passing a different value when calling the function."
      ],
      "metadata": {
        "id": "gOJXGoKJP-TM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4:** Modify Transcript Extraction from Audio\n",
        "\n",
        "This function will now handle both uploaded audio files and live recorded audio for transcription."
      ],
      "metadata": {
        "id": "v9zisiswQAhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert audio to text using Google Speech-to-Text API\n",
        "def transcribe_audio(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio file into the recognizer\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Capture the entire audio file\n",
        "\n",
        "    try:\n",
        "        # Use Google Web Speech API to transcribe the audio file\n",
        "        transcript_text = recognizer.recognize_google(audio)\n",
        "        print(\"Transcription Success! Transcript:\\n\", transcript_text)\n",
        "        return transcript_text\n",
        "    except sr.RequestError as e:\n",
        "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Google Speech Recognition could not understand the audio\")\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "fbqKAflbP_NV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5:** Ask User for Input Type (PDF, Audio, or Live Recording)\n",
        "\n",
        "Now, we modify the input selection to include live recording as an option, in addition to PDF and audio file uploads."
      ],
      "metadata": {
        "id": "NbtgvpI-QFwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask the user if they want to upload a PDF, an audio file, or do a live recording\n",
        "file_type = input(\"Would you like to upload a 'PDF', 'Audio', or 'Live' recording? \").strip().lower()\n",
        "\n",
        "# Initialize an empty transcript variable\n",
        "transcript = None\n",
        "\n",
        "if file_type == 'pdf':\n",
        "    # Handle PDF input\n",
        "    uploaded = files.upload()\n",
        "    for file_name in uploaded.keys():\n",
        "        with open(file_name, 'rb') as f:\n",
        "            transcript = f.read()\n",
        "\n",
        "    transcript_stream = BytesIO(transcript)\n",
        "    pdf_reader = PyPDF2.PdfReader(transcript_stream)\n",
        "\n",
        "    text = \"\"\n",
        "    for page_num in range(len(pdf_reader.pages)):\n",
        "        page = pdf_reader.pages[page_num]\n",
        "        text += page.extract_text()\n",
        "\n",
        "    print(\"Meeting Transcript Captured from PDF:\\n\", text)\n",
        "\n",
        "elif file_type == 'audio':\n",
        "    # Handle audio input\n",
        "    audio_uploaded = files.upload()\n",
        "    for audio_file_name in audio_uploaded.keys():\n",
        "        audio = AudioSegment.from_file(audio_file_name)\n",
        "        audio.export(\"transcript.wav\", format=\"wav\")\n",
        "        transcript = transcribe_audio(\"transcript.wav\")\n",
        "\n",
        "elif file_type == 'live':\n",
        "    # Handle live recording input\n",
        "    audio_file = record_live_audio(duration=60)  # Adjust duration as needed\n",
        "    transcript = transcribe_audio(audio_file)\n",
        "\n",
        "else:\n",
        "    print(\"Invalid choice. Please upload either 'PDF', 'Audio', or do a 'Live' recording.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "i2xvOmrmQHzc",
        "outputId": "70cecaac-f6f7-4f59-d400-26dad1c075eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Would you like to upload a 'PDF', 'Audio', or 'Live' recording? live\n",
            "Recording audio for 60 seconds...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PortAudioError",
          "evalue": "Error querying device -1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPortAudioError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7c321afda524>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mfile_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'live'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Handle live recording input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0maudio_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord_live_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust duration as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-fd6073c642fe>\u001b[0m in \u001b[0;36mrecord_live_audio\u001b[0;34m(duration, sample_rate)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Record audio with specified duration and sample rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mrecording\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduration\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait until the recording is finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36mrec\u001b[0;34m(frames, samplerate, channels, dtype, out, mapping, blocking, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     ctx.start_stream(InputStream, samplerate, ctx.input_channels,\n\u001b[0m\u001b[1;32m    277\u001b[0m                      ctx.input_dtype, callback, blocking, **kwargs)\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36mstart_stream\u001b[0;34m(self, StreamClass, samplerate, channels, dtype, callback, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   2607\u001b[0m                      blocking, **kwargs):\n\u001b[1;32m   2608\u001b[0m         \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Stop previous playback/recording\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2609\u001b[0;31m         self.stream = StreamClass(samplerate=samplerate,\n\u001b[0m\u001b[1;32m   2610\u001b[0m                                   \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2611\u001b[0m                                   \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, samplerate, blocksize, device, channels, dtype, latency, extra_settings, callback, finished_callback, clip_off, dither_off, never_drop_input, prime_output_buffers_using_stream_callback)\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \"\"\"\n\u001b[0;32m-> 1429\u001b[0;31m         _StreamBase.__init__(self, kind='input', wrap_callback='array',\n\u001b[0m\u001b[1;32m   1430\u001b[0m                              **_remove_self(locals()))\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, kind, samplerate, blocksize, device, channels, dtype, latency, extra_settings, callback, finished_callback, clip_off, dither_off, never_drop_input, prime_output_buffers_using_stream_callback, userdata, wrap_callback)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_samplesize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplerate\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 _get_stream_parameters(kind, device, channels, dtype, latency,\n\u001b[0m\u001b[1;32m    826\u001b[0m                                        extra_settings, samplerate)\n\u001b[1;32m    827\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36m_get_stream_parameters\u001b[0;34m(kind, device, channels, dtype, latency, extra_settings, samplerate)\u001b[0m\n\u001b[1;32m   2685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2686\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2687\u001b[0;31m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m         \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_channels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36mquery_devices\u001b[0;34m(device, kind)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPa_GetDeviceInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mPortAudioError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Error querying device {device}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructVersion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0mname_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPortAudioError\u001b[0m: Error querying device -1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6:** Use the Transcript for Summarization\n",
        "\n",
        "This step remains unchanged. Whether the transcript comes from a PDF, uploaded audio, or live recording, it will be summarized using the Google Gemini API."
      ],
      "metadata": {
        "id": "Kzs9ixy6QLK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to summarize the meeting transcript\n",
        "def summarize_meeting(transcript_text):\n",
        "    data = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"parts\": [\n",
        "                    {\"text\": transcript_text}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Make the POST request to the Summarization API\n",
        "        response = requests.post(summarization_url, headers=headers, json=data)\n",
        "\n",
        "        # Print the raw response for debugging\n",
        "        print(\"API Response Status Code:\", response.status_code)\n",
        "        print(\"API Response Content:\", response.text)\n",
        "\n",
        "        # Check if the request was successful\n",
        "        if response.status_code == 200:\n",
        "            return response.json()  # Return the parsed JSON response\n",
        "        else:\n",
        "            print(f\"Failed to summarize. Status Code: {response.status_code}\")\n",
        "            return None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Call the summarization function if transcript exists\n",
        "if transcript:\n",
        "    summary_response = summarize_meeting(transcript)\n",
        "    if summary_response and \"candidates\" in summary_response:\n",
        "        try:\n",
        "            summary = summary_response[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "            print(\"Meeting Summary:\\n\", summary)\n",
        "        except (IndexError, KeyError) as e:\n",
        "            print(f\"Error extracting summary from the response: {e}\")\n",
        "else:\n",
        "    print(\"No transcript available for summarization.\")\n"
      ],
      "metadata": {
        "id": "6Gzac30zQNeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7:** Chatbot for Asking Questions\n",
        "\n",
        "Finally, the chatbot functionality remains the same, allowing users to ask questions based on the generated summary."
      ],
      "metadata": {
        "id": "68tlAuuwQP9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to ask questions based on the summary\n",
        "def ask_question(question, summary_text):\n",
        "    prompt_data = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"parts\": [\n",
        "                    {\"text\": f\"{question}: {summary_text}\"}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(prompt_url, headers=headers, json=prompt_data)\n",
        "        print(\"Prompt API Response Status Code:\", response.status_code)\n",
        "        print(\"Prompt API Response Content:\", response.text)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            return response.json()  # Return the parsed JSON response\n",
        "        else:\n",
        "            print(f\"Failed to get an answer. Status Code: {response.status_code}\")\n",
        "            return None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "# Chatbot loop for asking questions\n",
        "if summary:\n",
        "    while True:\n",
        "        user_query = input(\"Ask a question about the meeting summary (or type 'exit' to quit): \")\n",
        "\n",
        "        if user_query.lower() == 'exit':\n",
        "            print(\"Exiting chatbot...\")\n",
        "            break\n",
        "\n",
        "        user_prompt_response = ask_question(user_query, summary)\n",
        "\n",
        "        if user_prompt_response and \"candidates\" in user_prompt_response:\n",
        "            try:\n",
        "                answer = user_prompt_response[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "                print(f\"Answer to your query:\\n{answer}\")\n",
        "            except (IndexError, KeyError) as e:\n",
        "                print(f\"Error accessing the answer in the response: {e}\")\n",
        "        else:\n",
        "            print(\"Response format is incorrect or no answer available.\")\n",
        "else:\n",
        "    print(\"No summary available to ask questions.\")\n"
      ],
      "metadata": {
        "id": "5-kLIuETQS9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How the Extended \"**Meeting Assistant AI**\" Works:\n",
        "\n",
        "    Install Dependencies: Includes the new sounddevice and wavio libraries for recording live audio.\n",
        "    Live Recording: Added functionality to record live audio from the user's microphone.\n",
        "    Choose Input Type: Users can now select between uploading a PDF, an audio file, or recording live audio.\n",
        "    Transcription & Summarization: The selected input (live audio, uploaded audio, or PDF) is transcribed and summarized.\n",
        "    Chatbot for Queries: Users can interact with the app by asking questions about the summarized meeting."
      ],
      "metadata": {
        "id": "VIaWuE1MQV7V"
      }
    }
  ]
}